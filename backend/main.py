#!/usr/bin/env python3
"""
Bet Copilot FastAPI Backend
Enterprise-grade betting analytics API with AI integration
"""

import os
import sqlite3
import requests
import subprocess
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional, Dict, Any
from contextlib import contextmanager
import logging

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from dotenv import load_dotenv
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Bet Copilot API",
    description="Enterprise-grade betting analytics with AI integration and autonomous operation",
    version="1.0.0"
)

# Initialize scheduler for autonomous operation
scheduler = AsyncIOScheduler()

# CORS middleware for frontend integration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Database path and API configuration
DB_PATH = Path(__file__).parent.parent / "database" / "bet_copilot.db"
LM_STUDIO_API_URL = os.getenv("LM_STUDIO_API_URL", "http://localhost:1234/v1/chat/completions")
ODDS_API_KEY = os.getenv("ODDS_API_KEY", "")
ODDS_API_URL = os.getenv("ODDS_API_URL", "https://api.the-odds-api.com/v4")

# Pydantic models
class BetCreate(BaseModel):
    matchup: str = Field(..., min_length=1, max_length=200)
    bet_type: str = Field(..., min_length=1, max_length=100)
    stake: float = Field(..., gt=0)
    odds: int = Field(..., ge=-1000, le=1000)

class BetSettle(BaseModel):
    result: str = Field(..., pattern="^(Won|Lost)$")

class BetResponse(BaseModel):
    bet_id: int
    matchup: str
    bet_type: str
    stake: float
    odds: int
    status: str
    profit_loss: float
    bet_date: str
    created_at: str
    updated_at: str

class DashboardStats(BaseModel):
    current_balance: float
    total_profit_loss: float
    roi: float
    win_rate: float
    total_bets: int
    pending_bets: int

class PredictionResponse(BaseModel):
    prediction_id: int
    matchup: str
    sport: str
    league: str
    game_date: str
    team_a: str
    team_b: str
    predicted_pick: str
    predicted_odds: int
    confidence_score: float
    projected_score: Optional[str]
    calculated_edge: Optional[float]
    created_at: str

class BetAIQuery(BaseModel):
    message: str = Field(..., min_length=1, max_length=1000)

class PerformanceDataPoint(BaseModel):
    date: str
    profit_loss: float
    running_balance: float
    cumulative_profit: float

class PerformanceHistory(BaseModel):
    data_points: List[PerformanceDataPoint]
    total_profit_loss: float
    total_bets: int
    win_rate: float
    roi: float
    best_day: float
    worst_day: float

# Database context manager
@contextmanager
def get_db():
    """Database connection context manager."""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

def calculate_profit_loss(stake: float, odds: int, won: bool) -> float:
    """Calculate profit/loss for a bet based on American odds."""
    if not won:
        return -stake  # Full stake is lost
    
    if odds > 0:
        # Positive odds: profit = stake * (odds/100)
        return stake * (odds / 100)
    else:
        # Negative odds: profit = stake / (abs(odds)/100)
        return stake / (abs(odds) / 100)

def get_current_balance() -> float:
    """Get current balance from ledger."""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT running_balance FROM ledger ORDER BY entry_id DESC LIMIT 1")
        result = cursor.fetchone()
        return result[0] if result else 0.0

# Autonomous Engine Functions
async def run_data_pipeline():
    """Autonomous data pipeline execution."""
    try:
        logger.info("ü§ñ Starting autonomous data pipeline...")
        pipeline_path = Path(__file__).parent / "data_pipeline.py"
        result = subprocess.run([sys.executable, str(pipeline_path)], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            logger.info("‚úÖ Data pipeline completed successfully")
        else:
            logger.error(f"‚ùå Data pipeline failed: {result.stderr}")
    except Exception as e:
        logger.error(f"‚ùå Data pipeline error: {e}")

async def run_model_training():
    """Autonomous model training execution."""
    try:
        logger.info("ü§ñ Starting autonomous model training...")
        trainer_path = Path(__file__).parent / "model_trainer.py"
        result = subprocess.run([sys.executable, str(trainer_path)], 
                              capture_output=True, text=True, timeout=600)
        
        if result.returncode == 0:
            logger.info("‚úÖ Model training completed successfully")
        else:
            logger.error(f"‚ùå Model training failed: {result.stderr}")
    except Exception as e:
        logger.error(f"‚ùå Model training error: {e}")

@app.on_event("startup")
async def startup_event():
    """Initialize autonomous scheduling on startup."""
    if os.getenv("ENABLE_SCHEDULER", "true").lower() == "true":
        try:
            # Schedule daily data pipeline at 3 AM
            data_hour = int(os.getenv("DATA_PIPELINE_HOUR", "3"))
            scheduler.add_job(
                run_data_pipeline,
                CronTrigger(hour=data_hour, minute=0),
                id="daily_data_pipeline",
                replace_existing=True
            )
            
            # Schedule weekly model training on Sunday at 3 AM
            training_day = int(os.getenv("MODEL_TRAINING_DAY", "6"))  # 6 = Sunday
            training_hour = int(os.getenv("MODEL_TRAINING_HOUR", "3"))
            scheduler.add_job(
                run_model_training,
                CronTrigger(day_of_week=training_day, hour=training_hour, minute=0),
                id="weekly_model_training",
                replace_existing=True
            )
            
            scheduler.start()
            logger.info("ü§ñ Autonomous scheduling engine initialized")
            logger.info(f"üìÖ Data pipeline scheduled daily at {data_hour:02d}:00")
            logger.info(f"üìÖ Model training scheduled weekly on day {training_day} at {training_hour:02d}:00")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize scheduler: {e}")
    else:
        logger.info("‚è∏Ô∏è Autonomous scheduling disabled by configuration")

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup scheduler on shutdown."""
    if scheduler.running:
        scheduler.shutdown()
        logger.info("üõë Autonomous scheduling engine stopped")

# API Endpoints

@app.get("/")
async def root():
    """Root endpoint with API information."""
    return {
        "message": "Bet Copilot API",
        "version": "1.0.0",
        "status": "active",
        "endpoints": {
            "dashboard": "/api/dashboard/stats",
            "bets": "/api/bets",
            "predictions": "/api/predictions",
            "betai": "/api/betai/query"
        }
    }

@app.get("/api/dashboard/stats", response_model=DashboardStats)
async def get_dashboard_stats():
    """Get real-time dashboard statistics via database aggregation."""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # Get current balance
        current_balance = get_current_balance()
        
        # Calculate total P/L from settled bets
        cursor.execute("""
            SELECT COALESCE(SUM(profit_loss), 0) as total_pl
            FROM bets 
            WHERE status IN ('Won', 'Lost')
        """)
        total_profit_loss = cursor.fetchone()[0]
        
        # Calculate total stakes for ROI
        cursor.execute("SELECT COALESCE(SUM(stake), 0) FROM bets")
        total_stakes = cursor.fetchone()[0]
        roi = (total_profit_loss / total_stakes * 100) if total_stakes > 0 else 0.0
        
        # Calculate win rate
        cursor.execute("SELECT COUNT(*) FROM bets WHERE status IN ('Won', 'Lost')")
        settled_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM bets WHERE status = 'Won'")
        won_count = cursor.fetchone()[0]
        
        win_rate = (won_count / settled_count * 100) if settled_count > 0 else 0.0
        
        # Count total and pending bets
        cursor.execute("SELECT COUNT(*) FROM bets")
        total_bets = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM bets WHERE status = 'Pending'")
        pending_bets = cursor.fetchone()[0]
        
        return DashboardStats(
            current_balance=current_balance,
            total_profit_loss=total_profit_loss,
            roi=roi,
            win_rate=win_rate,
            total_bets=total_bets,
            pending_bets=pending_bets
        )

@app.get("/api/bets", response_model=List[BetResponse])
async def get_bets(limit: int = 20):
    """Get recent bets."""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT * FROM bets 
            ORDER BY created_at DESC 
            LIMIT ?
        """, (limit,))
        
        rows = cursor.fetchall()
        return [BetResponse(**dict(row)) for row in rows]

@app.post("/api/bets", response_model=BetResponse)
async def create_bet(bet: BetCreate):
    """Create a new bet."""
    current_balance = get_current_balance()
    
    if current_balance < bet.stake:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Insufficient funds. Current balance: ${current_balance:.2f}"
        )
    
    with get_db() as conn:
        cursor = conn.cursor()
        now = datetime.now().isoformat()
        
        # Insert bet
        cursor.execute("""
            INSERT INTO bets (matchup, bet_type, stake, odds, bet_date, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (bet.matchup, bet.bet_type, bet.stake, bet.odds, now, now, now))
        
        bet_id = cursor.lastrowid
        
        # Update ledger
        new_balance = current_balance - bet.stake
        cursor.execute("""
            INSERT INTO ledger (timestamp, transaction_type, amount, running_balance, related_bet_id, description)
            VALUES (?, 'Bet Placed', ?, ?, ?, ?)
        """, (now, -bet.stake, new_balance, bet_id, f"Stake for bet #{bet_id}: {bet.matchup}"))
        
        conn.commit()
        
        # Return created bet
        cursor.execute("SELECT * FROM bets WHERE bet_id = ?", (bet_id,))
        row = cursor.fetchone()
        return BetResponse(**dict(row))

@app.put("/api/bets/{bet_id}/settle", response_model=BetResponse)
async def settle_bet(bet_id: int, settle: BetSettle):
    """Settle a pending bet."""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # Get bet
        cursor.execute("SELECT * FROM bets WHERE bet_id = ?", (bet_id,))
        bet_row = cursor.fetchone()
        
        if not bet_row:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Bet not found"
            )
        
        bet_dict = dict(bet_row)
        
        if bet_dict["status"] != "Pending":
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Bet is already settled as {bet_dict['status']}"
            )
        
        # Calculate profit/loss
        won = (settle.result == "Won")
        profit_loss = calculate_profit_loss(bet_dict["stake"], bet_dict["odds"], won)
        
        now = datetime.now().isoformat()
        
        # Update bet
        cursor.execute("""
            UPDATE bets 
            SET status = ?, profit_loss = ?, updated_at = ?
            WHERE bet_id = ?
        """, (settle.result, profit_loss, now, bet_id))
        
        # Update ledger if won
        if won and profit_loss > 0:
            current_balance = get_current_balance()
            new_balance = current_balance + profit_loss
            cursor.execute("""
                INSERT INTO ledger (timestamp, transaction_type, amount, running_balance, related_bet_id, description)
                VALUES (?, 'Bet Settled', ?, ?, ?, ?)
            """, (now, profit_loss, new_balance, bet_id, f"Winnings for bet #{bet_id}: {bet_dict['matchup']}"))
        
        conn.commit()
        
        # Return updated bet
        cursor.execute("SELECT * FROM bets WHERE bet_id = ?", (bet_id,))
        row = cursor.fetchone()
        return BetResponse(**dict(row))

async def fetch_live_odds(sport: str = "upcoming") -> List[Dict[str, Any]]:
    """Fetch live odds from The Odds API."""
    if not ODDS_API_KEY or ODDS_API_KEY == "your_odds_api_key_here":
        logger.warning("‚ö†Ô∏è No valid odds API key configured, using mock data")
        return []
    
    try:
        # Get upcoming games with odds
        url = f"{ODDS_API_URL}/sports/{sport}/odds"
        params = {
            "apiKey": ODDS_API_KEY,
            "regions": "us",
            "markets": "h2h,spreads,totals",
            "oddsFormat": "american",
            "dateFormat": "iso"
        }
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        
        return response.json()
    except Exception as e:
        logger.error(f"‚ùå Failed to fetch live odds: {e}")
        return []

def calculate_implied_probability(american_odds: int) -> float:
    """Convert American odds to implied probability."""
    if american_odds > 0:
        return 100 / (american_odds + 100) * 100
    else:
        return abs(american_odds) / (abs(american_odds) + 100) * 100

def calculate_edge(model_probability: float, market_odds: int) -> Optional[float]:
    """Calculate betting edge (+EV percentage)."""
    try:
        implied_probability = calculate_implied_probability(market_odds)
        edge = model_probability - implied_probability
        return round(edge, 2)
    except:
        return None

@app.get("/api/predictions", response_model=List[PredictionResponse])
async def get_predictions(limit: int = 10):
    """Get AI-generated ML predictions with live odds integration and edge calculation."""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # Get existing predictions
        cursor.execute("""
            SELECT * FROM predictions 
            ORDER BY created_at DESC 
            LIMIT ?
        """, (limit,))
        
        rows = cursor.fetchall()
        
        # If no predictions exist, generate new ones
        if not rows:
            logger.info("No predictions found, generating new LightGBM predictions...")
            try:
                trainer_path = Path(__file__).parent / "model_trainer.py"
                result = subprocess.run([sys.executable, str(trainer_path)], 
                                      capture_output=True, text=True, timeout=120)
                
                if result.returncode == 0:
                    logger.info("‚úÖ LightGBM model training completed successfully")
                    cursor.execute("""
                        SELECT * FROM predictions 
                        ORDER BY created_at DESC 
                        LIMIT ?
                    """, (limit,))
                    rows = cursor.fetchall()
                else:
                    logger.warning("‚ö†Ô∏è Model training failed, using fallback predictions")
                    # Generate enhanced fallback predictions with market simulation
                    fallback_predictions = [
                        {
                            "matchup": "Lakers vs Warriors",
                            "sport": "NBA",
                            "league": "NBA", 
                            "game_date": (datetime.now() + timedelta(days=1)).isoformat(),
                            "team_a": "Lakers",
                            "team_b": "Warriors",
                            "predicted_pick": "Lakers ML",
                            "predicted_odds": -125,
                            "confidence_score": 72.3,
                            "projected_score": "Lakers 116, Warriors 112",
                            "calculated_edge": 4.8,
                            "created_at": datetime.now().isoformat(),
                            "model_version": "v2.0-lightgbm-fallback"
                        },
                        {
                            "matchup": "Patriots vs Bills", 
                            "sport": "NFL",
                            "league": "NFL",
                            "game_date": (datetime.now() + timedelta(days=2)).isoformat(),
                            "team_a": "Patriots",
                            "team_b": "Bills",
                            "predicted_pick": "Bills -3.5",
                            "predicted_odds": -108,
                            "confidence_score": 68.7,
                            "projected_score": "Bills 27, Patriots 21",
                            "calculated_edge": 3.1,
                            "created_at": datetime.now().isoformat(),
                            "model_version": "v2.0-lightgbm-fallback"
                        },
                        {
                            "matchup": "Yankees vs Red Sox",
                            "sport": "MLB", 
                            "league": "MLB",
                            "game_date": (datetime.now() + timedelta(days=1)).isoformat(),
                            "team_a": "Yankees",
                            "team_b": "Red Sox",
                            "predicted_pick": "Yankees ML",
                            "predicted_odds": -140,
                            "confidence_score": 75.2,
                            "projected_score": "Yankees 8, Red Sox 5",
                            "calculated_edge": 5.4,
                            "created_at": datetime.now().isoformat(),
                            "model_version": "v2.0-lightgbm-fallback"
                        }
                    ]
                    
                    # Insert fallback predictions
                    for pred in fallback_predictions:
                        cursor.execute("""
                            INSERT INTO predictions (
                                matchup, sport, league, game_date, team_a, team_b,
                                predicted_pick, predicted_odds, confidence_score,
                                projected_score, calculated_edge, created_at, model_version
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            pred["matchup"], pred["sport"], pred["league"], pred["game_date"],
                            pred["team_a"], pred["team_b"], pred["predicted_pick"],
                            pred["predicted_odds"], pred["confidence_score"], pred["projected_score"],
                            pred["calculated_edge"], pred["created_at"], pred["model_version"]
                        ))
                    
                    conn.commit()
                    
                    # Fetch the newly created predictions
                    cursor.execute("""
                        SELECT * FROM predictions 
                        ORDER BY created_at DESC 
                        LIMIT ?
                    """, (limit,))
                    rows = cursor.fetchall()
                
            except Exception as e:
                logger.error(f"‚ùå Error generating LightGBM predictions: {e}")
        
        # Convert to prediction objects and enhance with live odds
        predictions = []
        live_odds_data = await fetch_live_odds()
        
        for row in rows:
            prediction = PredictionResponse(**dict(row))
            
            # Try to match with live odds and recalculate edge
            if live_odds_data:
                for game in live_odds_data:
                    # Simple matching logic (could be enhanced)
                    game_teams = f"{game.get('home_team', '')} vs {game.get('away_team', '')}"
                    if any(team in prediction.matchup for team in [game.get('home_team', ''), game.get('away_team', '')]):
                        # Find best odds for our prediction type
                        best_odds = None
                        for bookmaker in game.get('bookmakers', []):
                            for market in bookmaker.get('markets', []):
                                if market['key'] == 'h2h':  # Money line market
                                    for outcome in market['outcomes']:
                                        if prediction.predicted_pick.startswith(outcome['name']):
                                            if best_odds is None or abs(outcome['price']) < abs(best_odds):
                                                best_odds = outcome['price']
                        
                        if best_odds:
                            # Recalculate edge with live market odds
                            edge = calculate_edge(prediction.confidence_score, best_odds)
                            if edge is not None:
                                prediction.calculated_edge = edge
                                prediction.predicted_odds = best_odds
                        break
            
            predictions.append(prediction)
        
        # Sort by calculated edge (highest first) for +EV opportunities
        predictions.sort(key=lambda x: x.calculated_edge if x.calculated_edge else 0, reverse=True)
        
        return predictions

@app.get("/api/performance/history", response_model=PerformanceHistory)
async def get_performance_history():
    """Get historical performance data for visualization."""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # Get daily profit/loss aggregation from bets
        cursor.execute("""
            SELECT 
                DATE(created_at) as bet_date,
                SUM(CASE WHEN status = 'Won' THEN profit_loss WHEN status = 'Lost' THEN -stake ELSE 0 END) as daily_pl,
                COUNT(*) as bet_count
            FROM bets 
            WHERE status IN ('Won', 'Lost')
            GROUP BY DATE(created_at)
            ORDER BY bet_date ASC
        """)
        
        daily_results = cursor.fetchall()
        
        # Get overall statistics
        cursor.execute("""
            SELECT 
                COALESCE(SUM(profit_loss), 0) as total_pl,
                COUNT(*) as total_bets,
                COUNT(CASE WHEN status = 'Won' THEN 1 END) as wins,
                COUNT(CASE WHEN status = 'Lost' THEN 1 END) as losses,
                COALESCE(SUM(stake), 0) as total_stakes
            FROM bets 
            WHERE status IN ('Won', 'Lost')
        """)
        
        stats = cursor.fetchone()
        
        # Calculate performance metrics
        total_profit_loss = stats[0] if stats else 0.0
        total_bets = stats[1] if stats else 0
        wins = stats[2] if stats else 0
        losses = stats[3] if stats else 0
        total_stakes = stats[4] if stats else 0
        
        win_rate = (wins / (wins + losses) * 100) if (wins + losses) > 0 else 0.0
        roi = (total_profit_loss / total_stakes * 100) if total_stakes > 0 else 0.0
        
        # Build time series data
        data_points = []
        cumulative_profit = 0.0
        running_balance = 1000.0  # Starting balance
        best_day = 0.0
        worst_day = 0.0
        
        for row in daily_results:
            bet_date, daily_pl, bet_count = row
            cumulative_profit += daily_pl
            running_balance += daily_pl
            
            if daily_pl > best_day:
                best_day = daily_pl
            if daily_pl < worst_day:
                worst_day = daily_pl
            
            data_points.append(PerformanceDataPoint(
                date=bet_date,
                profit_loss=daily_pl,
                running_balance=running_balance,
                cumulative_profit=cumulative_profit
            ))
        
        # If no historical data, create sample point with current balance
        if not data_points:
            current_balance = get_current_balance()
            data_points.append(PerformanceDataPoint(
                date=datetime.now().strftime('%Y-%m-%d'),
                profit_loss=0.0,
                running_balance=current_balance,
                cumulative_profit=current_balance - 1000.0
            ))
        
        return PerformanceHistory(
            data_points=data_points,
            total_profit_loss=total_profit_loss,
            total_bets=total_bets,
            win_rate=win_rate,
            roi=roi,
            best_day=best_day,
            worst_day=worst_day
        )

@app.post("/api/betai/query")
async def query_betai(query: BetAIQuery):
    """Advanced RAG-powered AI query with comprehensive database context and LightGBM insights."""
    try:
        # Enhanced context retrieval with LightGBM insights
        context_data = []
        
        with get_db() as conn:
            cursor = conn.cursor()
            
            # Get recent predictions with model insights
            cursor.execute("""
                SELECT matchup, predicted_pick, confidence_score, calculated_edge, model_version,
                       projected_score, created_at
                FROM predictions 
                ORDER BY created_at DESC 
                LIMIT 8
            """)
            recent_predictions = cursor.fetchall()
            if recent_predictions:
                context_data.append("ü§ñ Recent AI Predictions (LightGBM Model):")
                for pred in recent_predictions:
                    edge_indicator = "üî•" if pred[3] and pred[3] > 4 else "üìä"
                    context_data.append(f"{edge_indicator} {pred[0]}: {pred[1]} ({pred[2]:.1f}% confidence, {pred[3]:.1f}% edge)")
                    if pred[5]:  # projected_score
                        context_data.append(f"   Projected: {pred[5]}")
                context_data.append("")
            
            # Get comprehensive betting performance analytics
            cursor.execute("""
                SELECT 
                    COALESCE(SUM(profit_loss), 0) as total_pl,
                    COUNT(*) as total_bets,
                    COUNT(CASE WHEN status = 'Won' THEN 1 END) as wins,
                    COUNT(CASE WHEN status = 'Lost' THEN 1 END) as losses,
                    COUNT(CASE WHEN status = 'Pending' THEN 1 END) as pending,
                    COALESCE(AVG(stake), 0) as avg_stake,
                    COALESCE(MAX(profit_loss), 0) as best_win,
                    COALESCE(MIN(profit_loss), 0) as worst_loss
                FROM bets 
            """)
            performance = cursor.fetchone()
            if performance and performance[1] > 0:
                win_rate = (performance[2] / (performance[2] + performance[3]) * 100) if (performance[2] + performance[3]) > 0 else 0
                total_risked = performance[1] * performance[5] if performance[5] > 0 else 0
                roi = (performance[0] / total_risked * 100) if total_risked > 0 else 0
                
                context_data.append("üìä Performance Analytics:")
                context_data.append(f"   Overall P&L: ${performance[0]:.2f} (ROI: {roi:.1f}%)")
                context_data.append(f"   Record: {performance[2]}-{performance[3]}-{performance[4]} ({win_rate:.1f}% win rate)")
                context_data.append(f"   Best Win: ${performance[6]:.2f} | Worst Loss: ${performance[7]:.2f}")
                context_data.append(f"   Average Stake: ${performance[5]:.2f}")
                context_data.append("")
            
            # Get recent betting activity with outcomes
            cursor.execute("""
                SELECT matchup, bet_type, stake, odds, status, profit_loss, created_at
                FROM bets 
                ORDER BY created_at DESC 
                LIMIT 8
            """)
            recent_bets = cursor.fetchall()
            if recent_bets:
                context_data.append("üí∞ Recent Betting Activity:")
                for bet in recent_bets:
                    status_emoji = "‚úÖ" if bet[4] == "Won" else "‚ùå" if bet[4] == "Lost" else "‚è≥"
                    pl_text = f" ({bet[5]:+.2f})" if bet[5] != 0 else ""
                    context_data.append(f"{status_emoji} {bet[0]} ({bet[1]}): ${bet[2]} at {bet[3]:+d}{pl_text}")
                context_data.append("")
            
            # Get current bankroll status
            cursor.execute("SELECT running_balance FROM ledger ORDER BY entry_id DESC LIMIT 1")
            balance = cursor.fetchone()
            if balance:
                context_data.append(f"üí≥ Current Bankroll: ${balance[0]:.2f}")
                context_data.append("")
        
        # Build comprehensive context
        context = "\n".join(context_data) if context_data else "No recent data available."
        
        # Enhanced system prompt with LightGBM and RAG context
        system_prompt = f"""You are BetAI, an elite sports betting analyst powered by advanced machine learning. You have access to a state-of-the-art LightGBM prediction model and comprehensive user data.

CURRENT USER DATA & ML INSIGHTS:
{context}

CORE CAPABILITIES:
- Advanced LightGBM model analysis with feature engineering (rolling averages, strength of schedule, head-to-head)
- Comprehensive betting performance analytics and pattern recognition
- Strategic bankroll management and risk assessment
- Real-time prediction interpretation and edge identification

ANALYSIS FRAMEWORK:
1. Data-Driven Insights: Reference specific predictions, confidence scores, and calculated edges
2. Performance Context: Analyze user's betting patterns, win rates, and ROI trends  
3. Risk Management: Assess position sizing relative to bankroll and recent performance
4. Strategic Recommendations: Provide actionable insights based on model outputs and user history

RESPONSE GUIDELINES:
- Lead with specific, quantitative insights from the LightGBM model when relevant
- Reference actual user data and performance metrics
- Provide strategic context for predictions (why the model favors certain outcomes)
- Emphasize disciplined bankroll management (1-3% position sizing)
- Explain edge calculations and confidence thresholds
- Be concise but comprehensive, focusing on actionable intelligence

Remember: You're not just analyzing odds - you're providing strategic intelligence based on advanced ML predictions and user-specific performance data."""

        # Prepare enhanced request to LM Studio
        payload = {
            "model": "local-model",
            "messages": [
                {
                    "role": "system", 
                    "content": system_prompt
                },
                {
                    "role": "user", 
                    "content": query.message
                }
            ],
            "temperature": 0.7,
            "max_tokens": 600,
            "stop": None
        }
        
        # Make request to LM Studio with enhanced error handling
        response = requests.post(
            LM_STUDIO_API_URL,
            json=payload,
            timeout=45,
            headers={"Content-Type": "application/json"}
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result.get("choices", [{}])[0].get("message", {}).get("content", "No response from AI")
            return {"response": ai_response}
        else:
            # Enhanced fallback response with ML context
            fallback_response = f"""ü§ñ BetAI (LightGBM Intelligence - Offline Mode)

I'm currently running on fallback intelligence while the LM Studio connection is restored. Here's what I can tell you based on your data:

{context}

QUESTION: "{query.message}"

ANALYSIS (Based on Available Data):
‚Ä¢ Our LightGBM model shows recent predictions with confidence scores ranging 68-75%
‚Ä¢ Look for predictions with calculated edge > 4% for stronger value opportunities  
‚Ä¢ Current performance metrics indicate the importance of consistent position sizing
‚Ä¢ Recommend focusing on high-confidence model outputs (>70%) given recent patterns

STRATEGIC GUIDANCE:
‚Ä¢ Maintain 1-3% position sizing relative to current bankroll
‚Ä¢ Prioritize predictions with both high confidence AND significant edge calculations
‚Ä¢ Monitor model version updates (currently v2.0-lightgbm) for enhanced accuracy

For detailed ML model explanations and advanced analysis, please ensure LM Studio is running on localhost:1234."""
            return {"response": fallback_response}
            
    except requests.exceptions.Timeout:
        return {"response": "‚è±Ô∏è BetAI response timeout. The AI is processing complex analysis - please try again. Ensure LM Studio has sufficient resources allocated."}
    except requests.exceptions.ConnectionError:
        # Comprehensive offline analysis
        try:
            offline_context = "Unable to retrieve recent data"
            with get_db() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT running_balance FROM ledger ORDER BY entry_id DESC LIMIT 1")
                balance = cursor.fetchone()
                cursor.execute("SELECT COUNT(*) FROM predictions WHERE model_version LIKE '%lightgbm%'")
                lgb_predictions = cursor.fetchone()
                
                if balance and lgb_predictions:
                    offline_context = f"Current Balance: ${balance[0]:.2f} | LightGBM Predictions Available: {lgb_predictions[0]}"
        except:
            offline_context = "Limited data access in offline mode"
            
        return {"response": f"üîå BetAI is offline. LM Studio connection failed. {offline_context}\n\nPlease start LM Studio on localhost:1234 for full AI analysis capabilities."}
    except Exception as e:
        return {"response": f"‚ö†Ô∏è BetAI encountered an analysis error: {str(e)}\n\nThis may indicate a model processing issue. Please verify system resources and try again."}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)